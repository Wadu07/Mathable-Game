{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T14:59:33.189691Z",
     "start_time": "2024-06-23T14:59:33.185979Z"
    }
   },
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T14:59:33.707943Z",
     "start_time": "2024-06-23T14:59:33.460767Z"
    }
   },
   "cell_type": "code",
   "source": "model = YOLO(\"yolov9e\")",
   "id": "9575023cf549cbb1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T14:59:33.737830Z",
     "start_time": "2024-06-23T14:59:33.732718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parking_slots = [\n",
    "    [(1603, 834), (1785,885),(1754, 1047), (1560, 1040)],#1\n",
    "    [(1468, 745), (1615, 799),(1555, 1037), (1401, 928)],#2\n",
    "    [(1355, 677), (1471,710),(1393, 919), (1268, 832)],#3\n",
    "    [(1250, 622), (1342,662),(1265, 826), (1164, 752)],#4\n",
    "    [(1176, 571), (1257,603),(1160, 748), (1077, 683)],#5\n",
    "    [(1101, 528), (1151,570),(1075, 680), (1001, 627)],#6\n",
    "    [(1031, 486), (1102,516),(1000, 626), (937, 581)],#7\n",
    "    [(976, 439), (1037,482),(925, 581), (876, 538)],#8\n",
    "    [(935, 411), (992,432),(876, 536), (831, 502)],#9\n",
    "    [(881, 375), (941,418),(830, 494), (786, 471)]#10\n",
    "] "
   ],
   "id": "5858aa8d00e0ca40",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:23:53.601304Z",
     "start_time": "2024-06-23T15:23:53.581241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#function to get the last frame of the video\n",
    "def get_last_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
    "    success, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not success:\n",
    "        raise ValueError(\"Could not read the last frame.\")\n",
    "    return frame\n",
    "\n",
    "# here we check if the center of the car is in the slot\n",
    "def is_center_in_slot(center, slot):\n",
    "    slot_arr = np.array(slot, np.int32).reshape((-1, 1, 2))\n",
    "    return cv2.pointPolygonTest(slot_arr, center, False) >= 0\n",
    "\n",
    "\n",
    "#write the detections in a file\n",
    "def write_in_txt(filename, detected_occupied_slots):\n",
    "    with open(filename, 'w') as file:\n",
    "        for slot, status in detected_occupied_slots.items():\n",
    "            file.write(f\"{status}\\n\") #we just write the status of the slot in the file\n",
    "\n",
    "def predict_detections(image, parking_slots, model):\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # perform the inference with classes car and trucks (2, 7)\n",
    "    results = model.predict(image_rgb, classes=[2, 7], verbose=False)\n",
    "    \n",
    "    # get the bounding boxes and classes\n",
    "    detections = results[0].boxes.xyxy  #bounding boxes\n",
    "    classes = results[0].boxes.cls  #classes\n",
    "     \n",
    "    #here we calculate the center of detections\n",
    "    centers = []\n",
    "    for detection, cls in zip(detections, classes):\n",
    "        if int(cls) == 2 or int(cls) == 7:  #we are interested only in cars and trucks\n",
    "            x_min, y_min, x_max, y_max = detection[:4] #here we get the coordinates of the bounding box\n",
    "            center_x = int((x_min + x_max) / 2) #we calculate the average of the x coordinates\n",
    "            center_y = int((y_min + y_max) / 2) #calculate the average of the y coordinates\n",
    "            centers.append((center_x, center_y)) #for every center calculated we append it to the centers list\n",
    "    \n",
    "    #we create a dictionary to store the detected occupied slots\n",
    "    detected_occupied_slots = {slot_num: 0 for slot_num in range(1, 11)}\n",
    "    for (center_x, center_y) in centers:\n",
    "        point = (center_x, center_y)\n",
    "        for index, slot in enumerate(parking_slots):\n",
    "            if is_center_in_slot(point, slot): #if the center of the car is in the slot\n",
    "                detected_occupied_slots[index + 1] = 1  #we mark the slot as occupied\n",
    "    \n",
    "    return detected_occupied_slots  #return the dictionary with the detected occupied slots\n",
    "\n",
    "\n",
    "\n",
    "#we handle the videos from the folder\n",
    "def process_videos_for_task2(video_folder, output_folder, parking_slots, model):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')] #we get the video files from the folder\n",
    "    \n",
    "    #for every video file we process the video and generate the detection file\n",
    "    for filename in tqdm(video_files, desc=\"Processing videos\"):\n",
    "        video_path = os.path.join(video_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename.replace('.mp4', '_det.txt'))\n",
    "        \n",
    "        #we get last frame of the video\n",
    "        last_frame = get_last_frame(video_path)\n",
    "        #predict the detections\n",
    "        detected_occupied_slots = predict_detections(last_frame, parking_slots, model)\n",
    "        #write the detections in a file\n",
    "        write_in_txt(output_path, detected_occupied_slots)\n",
    "\n",
    "# # Function to compare generated files with ground truth and visualize discrepancies\n",
    "# def compare_with_ground_truth(ground_truth_folder, output_folder, video_folder, parking_slots):\n",
    "#     ground_truth_files = [f for f in os.listdir(ground_truth_folder) if f.endswith('_gt.txt')]\n",
    "#     total_correct = 0\n",
    "#     total_slots = 0\n",
    "#     mismatches = []\n",
    "# \n",
    "#     for gt_file in ground_truth_files:\n",
    "#         gt_path = os.path.join(ground_truth_folder, gt_file)\n",
    "#         output_path = os.path.join(output_folder, gt_file.replace('_gt.txt', '_det.txt'))\n",
    "#         video_path = os.path.join(video_folder, gt_file.replace('_gt.txt', '.mp4'))\n",
    "# \n",
    "#         if not os.path.exists(output_path):\n",
    "#             print(f\"Missing detection file for {gt_file}\")\n",
    "#             continue\n",
    "# \n",
    "#         with open(gt_path, 'r') as gt, open(output_path, 'r') as out:\n",
    "#             gt_slots = [int(line.strip()) for line in gt.readlines()]\n",
    "#             out_slots = [int(line.strip()) for line in out.readlines()]\n",
    "# \n",
    "#             if len(gt_slots) != len(out_slots):\n",
    "#                 print(f\"Mismatch in number of slots for {gt_file}\")\n",
    "#                 continue\n",
    "# \n",
    "#             for idx, (gt_status, out_status) in enumerate(zip(gt_slots, out_slots)):\n",
    "#                 if gt_status != out_status:\n",
    "#                     mismatches.append((video_path, idx + 1, gt_status, out_status))\n",
    "#                 else:\n",
    "#                     total_correct += 1\n",
    "#                 total_slots += 1\n",
    "# \n",
    "#     accuracy = total_correct / total_slots if total_slots > 0 else 0\n",
    "#     print(f'Accuracy: {accuracy:.2f}')\n",
    "\n"
   ],
   "id": "39dcba9d0c52264b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:39:54.106788Z",
     "start_time": "2024-06-23T15:39:51.024555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "video_folder = '/home/radu/Facultate/Computer_Vision/Project2/train/Task2/'\n",
    "output_folder = '/home/radu/Facultate/Computer_Vision/Project2/train/Task2/output/'\n",
    "ground_truth_folder = '/home/radu/Facultate/Computer_Vision/Project2/train/Task2/ground-truth/'\n",
    "\n",
    "\n",
    "# apply the function to process the videos and generate the detection files\n",
    "process_videos_for_task2(video_folder, output_folder, parking_slots, model)\n",
    "print(\"The txt files are generated\")\n",
    "# Compare generated detection files with ground truth\n",
    "# compare_with_ground_truth(ground_truth_folder, output_folder, video_folder, parking_slots)"
   ],
   "id": "38ba4b56c9d54dda",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 15/15 [00:03<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The txt files are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66332e7d16c66e4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
